{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 256 pairs in total\n",
      "After Filtering: 84 pairs left\n",
      "After Verification: 6 similar pairs\n",
      "(precision, recall, fmeasure) =  (1.0, 0.375, 0.5454545454545454)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class SimilarityJoin:\n",
    "    def __init__(self, data_file1, data_file2):\n",
    "        self.df1 = pd.read_csv(data_file1)\n",
    "        self.df2 = pd.read_csv(data_file2)\n",
    "\n",
    "    def preprocess_df(self, df, cols): \n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\" \n",
    "        df[cols[0]] =df[cols[0]].fillna('')\n",
    "        df[cols[1]] =df[cols[1]].fillna('')\n",
    "\n",
    "        df['joinKey'] = df[cols[0]].astype(str)+\" \"+df[cols[1]].astype(str)\n",
    "        df['joinKey'] = df['joinKey'].apply(lambda x: x.lower())\n",
    "        df['joinKey'] = df['joinKey'].apply(lambda x:re.split(r'\\W+',x))\n",
    "        df['joinKey'] = df['joinKey'].apply(lambda x:list(filter(None,x)) )\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def filtering(self, df1, df2):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "\n",
    "        df1_flatten = df1.explode('joinKey')\n",
    "        df1_flatten = df1_flatten[['id','joinKey']].rename(columns={'id':'id1'})\n",
    "        df2_flatten = df2.explode('joinKey')\n",
    "        df2_flatten = df2_flatten[['id','joinKey']].rename(columns={'id':'id2'})\n",
    "        \n",
    "        can_df = df1_flatten.merge(df2_flatten,on='joinKey')\n",
    "        can_df = can_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        df1 = df1.rename(columns={'id':'id1','joinKey':'joinKey1'})\n",
    "        can_df = can_df.merge(df1,on='id1')\n",
    "        can_df = can_df[['id1','id2','joinKey1']]\n",
    "\n",
    "        df2 = df2.rename(columns={'id':'id2','joinKey':'joinKey2'})\n",
    "        can_df = can_df.merge(df2,on='id2')\n",
    "        can_df = can_df[['id1','joinKey1','id2','joinKey2']]\n",
    "        can_df=can_df.loc[can_df.astype(str).drop_duplicates().index]\n",
    "\n",
    "#         can_df.to_csv('test.csv', encoding='utf-8', index=False)\n",
    "        return can_df\n",
    "        \n",
    "    \n",
    "    def verification(self, cand_df, threshold):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "        def jaccard_similarity(list1, list2):\n",
    "            s1 = set(list1)\n",
    "            s2 = set(list2)\n",
    "            return len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "        \n",
    "        result_df = cand_df.copy()\n",
    "        result_df['jaccard'] = cand_df.apply(lambda x: jaccard_similarity(x['joinKey1'],x['joinKey2']),axis=1)\n",
    "        result_df = result_df[result_df.jaccard >= threshold ]\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def evaluate(self, result, ground_truth):\n",
    "        \"\"\"\n",
    "            Write your code!\n",
    "        \"\"\"\n",
    "        tuple_result = [tuple(t) for t in result]\n",
    "        tuple_ground_truth = [tuple(t) for t in ground_truth]\n",
    "\n",
    "        number_match = len(set(tuple_result) & set(tuple_ground_truth))\n",
    "        \n",
    "        precision = number_match/len(result)\n",
    "        recall = number_match/len(ground_truth)\n",
    "        f_score = (2*precision*recall)/(precision+recall) \n",
    "\n",
    "        return (precision,recall,f_score)\n",
    "\n",
    "    def jaccard_join(self, cols1, cols2, threshold):\n",
    "        new_df1 = self.preprocess_df(self.df1, cols1)\n",
    "        new_df2 = self.preprocess_df(self.df2, cols2)\n",
    "        print (\"Before filtering: %d pairs in total\" %(self.df1.shape[0] *self.df2.shape[0])) \n",
    "        cand_df = self.filtering(new_df1, new_df2)\n",
    "        print (\"After Filtering: %d pairs left\" %(cand_df.shape[0]))\n",
    "\n",
    "        result_df = self.verification(cand_df, threshold)\n",
    "        print (\"After Verification: %d similar pairs\" %(result_df.shape[0]))\n",
    "\n",
    "        return result_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    er = SimilarityJoin(\"Amazon_sample.csv\", \"Google_sample.csv\")\n",
    "    amazon_cols = [\"title\", \"manufacturer\"]\n",
    "    google_cols = [\"name\", \"manufacturer\"]\n",
    "    result_df = er.jaccard_join(amazon_cols, google_cols, 0.5)\n",
    "\n",
    "    result = result_df[['id1', 'id2']].values.tolist()\n",
    "    ground_truth = pd.read_csv(\"Amazon_Google_perfectMapping_sample.csv\").values.tolist()\n",
    "    print (\"(precision, recall, fmeasure) = \", er.evaluate(result, ground_truth))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
