{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Hypothesis Testing (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we cannot get the full population but only a sample. If we derive an interesting result from a sample, how likely can we derive the same result from the entire population? In other words, we want to know whether this result is a true finding or it just happens in the sample by chance. Hypothesis testing aims to answer this fundamental question. \n",
    "\n",
    "\n",
    "**Hypothesis Testing**\n",
    "1. Why A/B testing?  \n",
    "2. What is a permutation test? How to implement it?\n",
    "3. What is p-value? How to avoid p-hacking? \n",
    "4. What is a chi-squared test? How to implement it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. A/B Testing\n",
    "> Acknowledgment: Thank [Greg Baker](http://www.cs.sfu.ca/~ggbaker/) for helping me to prepare this task.\n",
    "\n",
    "A very common technique to evaluate changes in a user interface is A/B testing: show some users interface A, some interface B, and then look to see if one performs better than the other.\n",
    "\n",
    "Suppose I started an A/B test on CourSys. Here are the two interfaces that I want to compare with. I want to know whether a good placeholder in the search box can attract more users to use the `search` feature.\n",
    "\n",
    "\n",
    "![](img/ab-testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided [searchlog.json](searchlog.json) has information about users' usage. The question I was interested in: is the number of searches per user different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to first pick up a **test statistic** to quantify how good an interface is. Here, we choose \"the search_count mean\". \n",
    "\n",
    "Please write the code to compute **the difference of the search_count means between interface A and Interface B.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          uid  is_instructor search_ui  search_count\n",
      "0     6061521           True         A             2\n",
      "1    11986457          False         A             0\n",
      "2    15995765          False         A             0\n",
      "3     9106912           True         B             0\n",
      "4     9882383          False         A             0\n",
      "..        ...            ...       ...           ...\n",
      "676  16768212          False         B             0\n",
      "677   7643715           True         A             0\n",
      "678  14838641          False         A             0\n",
      "679   6454817          False         A             0\n",
      "680   9276990          False         B             3\n",
      "\n",
      "[681 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>search_count</th>\n",
       "      <th>search_count</th>\n",
       "      <th>search_count</th>\n",
       "      <th>search_count</th>\n",
       "      <th>search_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_ui</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>231</td>\n",
       "      <td>348</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>2.125832</td>\n",
       "      <td>1.458023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>266</td>\n",
       "      <td>333</td>\n",
       "      <td>0.798799</td>\n",
       "      <td>2.516625</td>\n",
       "      <td>1.586387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sum          len         mean          var          std\n",
       "          search_count search_count search_count search_count search_count\n",
       "search_ui                                                                 \n",
       "A                  231          348     0.663793     2.125832     1.458023\n",
       "B                  266          333     0.798799     2.516625     1.586387"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_json('searchlog.json', lines=True)\n",
    "# ab_summary = data.pivot_table(values='search_count', index='search_ui', aggfunc=np.sum)\n",
    "# ab_summary['total'] = data.pivot_table(values='search_count', index='search_ui', aggfunc=lambda x: len(x))\n",
    "# ab_summary['means'] = data.pivot_table(values='search_count', index='search_ui')\n",
    "# print(ab_summary)\n",
    "print(data)\n",
    "\n",
    "ab_summary2 = data.pivot_table(values='search_count',index='search_ui',aggfunc=[np.sum,len,np.mean,np.var,np.std])\n",
    "ab_summary2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we find that the mean value increased by 0.135. Then, we wonder whether this result is just caused by random variation. \n",
    "\n",
    "We define the Null Hypothesis as\n",
    " * The difference in search_count mean between Interface A and Interface B is caused by random variation. \n",
    " \n",
    "Then the next job is to check whether we can reject the null hypothesis or not. If it does, we can adopt the alternative explanation:\n",
    " * The difference in search_count mean  between Interface A and Interface B is caused by the design differences between the two.\n",
    "\n",
    "We compute the p-value of the observed result. If p-value is low (e.g., <0.01), we can reject the null hypothesis, and adopt  the alternative explanation.  \n",
    "\n",
    "Please implement a permutation test (numSamples = 10000) to compute the p-value. Note that you are NOT allowed to use an implementation in an existing library. You have to implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library t = -1.1548592629736951\n",
      "library p = 0.2485609905408175\n",
      "p value:  0.2459\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "from scipy import stats\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "\n",
    "data_A = data[data['search_ui']=='A']\n",
    "data_B = data[data['search_ui']=='B']\n",
    "t, p = stats.ttest_ind(data_A.search_count,data_B.search_count,equal_var=False)\n",
    "print(\"library t = \" + str(t))\n",
    "print(\"library p = \" + str(p))\n",
    "\n",
    "def permutation_test(A, B, num_sample=10000):\n",
    "    num_A = len(A)\n",
    "    diff_A_B = np.abs(np.mean(A) - np.mean(B))\n",
    "    A_B = np.concatenate([A, B])\n",
    "    counter = 0\n",
    "    for _ in range(num_sample):\n",
    "        np.random.shuffle(A_B)\n",
    "        counter += diff_A_B < np.abs(np.mean(A_B[:num_A]) - np.mean(A_B[num_A:]))\n",
    "    return counter / num_sample\n",
    "print(\"p value: \",permutation_test(data_A.search_count, data_B.search_count, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to use the same dataset to do another A/B testing. We suspect that instructors are the ones who can get more useful information from the search feature, so perhaps non-instructors didn't touch the search feature because it was genuinely not relevant to them.\n",
    "\n",
    "So we decide to repeat the above analysis looking only at instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. If using the same dataset to do this analysis, do you feel like we're p-hacking? If so, what can we do with it? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** I think it is a p-hacking since the original UI collects data from both instructors and non-instructors. Therefore, we should not use the same dataset. If we want to do A/B analysis again, it is better to collect new data (in this case, the UI should be allowed for only instructors). In general, avoiding p-hacking comes down to awareness, planning ahead, and being open when post-hoc manipulation is legitimately needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Chi-squared Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tens of different hypothesis testing methods. It's impossible to cover all of them in one week. Given that this is an important topic in statistics, I highly recommend using your free time to learn some other popular ones such as <a href=\"https://en.wikipedia.org/wiki/Chi-squared_test\">Chi-squared test</a>, <a href=\"https://en.wikipedia.org/wiki/G-test\">G-test</a>, <a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\">T-test</a>, and <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mann–Whitney U test</a>.\n",
    "\n",
    "On the searchlog dataset, there are two categorical columns: `is_instructor` and `search_ui`. In Task D, your job is to first learn how a Chi-Squired test works by yourself and then use it to test whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to compute the Chi-squared stat. Note that you are **not** allowed to call an existing function (e.g., stats.chi2, chi2_contingency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_ui        A    B  All\n",
      "is_instructor               \n",
      "False          233  213  446\n",
      "True           115  120  235\n",
      "All            348  333  681\n",
      "Chi-squared Statistic: 0.6731740891275046\n",
      "P value:  0.41194715912043356\n",
      "\n",
      "\n",
      "library value without Yates' correction for continuity:  (0.6731740891275046, 0.41194715912043356, 1, array([[227.91189427, 218.08810573],\n",
      "       [120.08810573, 114.91189427]]))\n",
      "library value:  (0.5473712356215867, 0.459393799574249, 1, array([[227.91189427, 218.08810573],\n",
      "       [120.08810573, 114.91189427]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To check expected values\\nfrom scipy.stats.contingency import expected_freq\\nprint(expected_freq(f_obs))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "# Test value with library\n",
    "import pandas\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data = pd.read_json('searchlog.json', lines=True)\n",
    "contingency_table = pd.crosstab(\n",
    "    data['is_instructor'],\n",
    "    data['search_ui'],\n",
    "    margins = True\n",
    ")\n",
    "print(contingency_table)\n",
    "row_sums = contingency_table.iloc[0:2,2].values\n",
    "col_sums = contingency_table.iloc[2,0:2].values\n",
    "total = contingency_table.loc['All', 'All']\n",
    "f_obs = np.append(contingency_table.iloc[0][0:2].values, contingency_table.iloc[1][0:2].values)\n",
    "f_expected = []\n",
    "for j in range(2):\n",
    "    for col_sum in col_sums:\n",
    "        f_expected.append(col_sum*row_sums[j]/total)\n",
    "chi_squared_statistic = ((f_obs - f_expected)**2/f_expected).sum()\n",
    "print('Chi-squared Statistic: {}'.format(chi_squared_statistic))\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_statistic,  # Find the p-value\n",
    "                             df=1)\n",
    "print(\"P value: \",p_value)\n",
    "\n",
    "### Check with library\n",
    "f_obs = np.array([contingency_table.iloc[0][0:2].values,\n",
    "                  contingency_table.iloc[1][0:2].values])\n",
    "from scipy import stats\n",
    "print(\"\\n\\nlibrary value without Yates' correction for continuity: \", stats.chi2_contingency(f_obs,correction=False))\n",
    "print(\"library value: \", stats.chi2_contingency(f_obs))\n",
    "\n",
    "''' To check expected values\n",
    "from scipy.stats.contingency import expected_freq\n",
    "print(expected_freq(f_obs))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain how to use Chi-squared test to determine whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** So sincec p-value is greater than 1% we can reject our hull hypothesis. Chi square is a non-parametric test that is used to show association between two qualitative variables (in this case: is_instructor and search_ui) ; while correlation is used to test the correlation between two quantitative variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
